{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cca937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this notebook, the word \"sentences\" is used instead of \"section contents\" like in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlikely-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sticky-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_categories_into_connected_components(articles_categories_file,wcnoutput_file):\n",
    "    \n",
    "    # we get the set of article ids which have at least one section after filtering out unique sections\n",
    "    articles_with_sections=set(load_json(\"../data/article_sections_filtered.json\", object_hook=article_sections_object_hook).keys())\n",
    "\n",
    "    # while in memory, we use category ids insead of their titles to save memory\n",
    "    # (because the same category appears multiple times)\n",
    "    category_title_to_id_map=get_category_title_to_id_map()\n",
    "    category_id_to_title_map={v:k for k,v in category_title_to_id_map.items()}\n",
    "            \n",
    "    # we ignore \"container categories\" ie categories which are supposed to contain only subcategories\n",
    "    # see https://en.wikipedia.org/wiki/Category:Container_categories\n",
    "    # in the dataset from March 2021, there is one article in the category \"Births\" which is supposed\n",
    "    # to be a container category\n",
    "    # this avoids that the majority of categories are in the same connected component because of a minority\n",
    "    # of articles which were not supposed to be in those categories have connected together many categories\n",
    "    container_categories=set()\n",
    "    with open(\"../data/category_graph.tsv\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            category=split_line[0]\n",
    "            parent_category=split_line[1]\n",
    "            if parent_category==\"Container_categories\":\n",
    "                container_categories.add(category_title_to_id_map[category])\n",
    "                \n",
    "    # we ignore categories which are not ontologically pure enough,\n",
    "    # because these will not provide sections for recommendation\n",
    "    pure_categories=set()\n",
    "    # key: category, value: articles which contribute to this category's section counts\n",
    "    category_articles_wcn={}\n",
    "    with open(wcnoutput_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            line_dict = json.loads(line)\n",
    "            category = line_dict['category']\n",
    "            category_id=category_title_to_id_map[category]\n",
    "            pure_categories.add(category_id)\n",
    "            articles=line_dict['articles']\n",
    "            category_articles_wcn[category_id]=set(articles)\n",
    "\n",
    "            \n",
    "    # key: article id, value: list of categories to which article belongs\n",
    "    article_categories={}\n",
    "    with open(articles_categories_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            article_id = int(split_line[0])\n",
    "            if article_id not in articles_with_sections:\n",
    "                continue\n",
    "            category = split_line[2]\n",
    "            category_id=category_title_to_id_map[category]\n",
    "            if category_id not in pure_categories:\n",
    "                continue\n",
    "            if category_id in container_categories:\n",
    "                continue\n",
    "            if article_id not in article_categories.keys():\n",
    "                article_categories[article_id]=[]\n",
    "            article_categories[article_id].append(category_id)\n",
    "\n",
    "    g=nx.Graph()\n",
    "    for article_id,categories in tqdm(article_categories.items()):\n",
    "        if len(categories)==1:\n",
    "            g.add_node(categories[0])\n",
    "        else:\n",
    "            categoryA=categories[0]\n",
    "            # because we want only to detect connected component, we do not need to connect all the edges together\n",
    "            # having all categories (B) for a given article connected to a single common category (A)\n",
    "            # is sufficient for detecting connected components\n",
    "            for categoryB in categories[1:]:\n",
    "                g.add_edge(categoryA,categoryB)\n",
    "    with open(\"../data/categories_splitted_into_connected_components.json\", \"a+\") as f_out:\n",
    "        for categories in tqdm(nx.connected_components(g)):\n",
    "            category_names=[category_id_to_title_map[category_id] for category_id in categories]\n",
    "            f_out.write(json.dumps({'categories':category_names})+\"\\n\")\n",
    "            \n",
    "    return article_categories,category_title_to_id_map,category_id_to_title_map,category_articles_wcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "laden-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_categories_file=\"../data/article_categories_no_unknown_types.tsv\"\n",
    "wcnoutput_file=\"../data/gini_articles_scores_0985_no_unknown_type.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confirmed-holiday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article_categories,category_title_to_id_map,category_id_to_title_map,category_articles_wcn=split_categories_into_connected_components(articles_categories_file,wcnoutput_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applicable-monkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfe001cff6e4d8d9123fa5fa1337ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1737697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# key: category id, value: set of articles which belongs to this category\n",
    "category_articles={}\n",
    "for article,categories in tqdm(article_categories.items()):\n",
    "    for category_id in categories:\n",
    "        if category_id not in category_articles.keys():\n",
    "            category_articles[category_id]=set()\n",
    "        category_articles[category_id].add(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affected-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: article_id, value: list of categories to which this article contribute with its sections\n",
    "article_categories_wcn={}\n",
    "for category,articles in category_articles_wcn.items():\n",
    "    for article in articles:\n",
    "        if article not in article_categories_wcn.keys():\n",
    "            article_categories_wcn[article]=[]\n",
    "        article_categories_wcn[article].append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hired-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key: article_id, value: sections in article\n",
    "article_sections=load_json(\"../data/article_sections_filtered.json\", object_hook=article_sections_object_hook)\n",
    "\n",
    "#key: category_id, value: set of sections that will be included in recommendations for given categry\n",
    "category_top_sections={category_title_to_id_map[category]:set(sections) for category,sections in json.loads(open(\"../data/category_top_sections.json\", encoding=\"utf8\").read()).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bearing-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the critera used to stop spliting categories into communities is the total number of section contents\n",
    "# inside a given category community\n",
    "# we will use some of the biggest numbers of section contents in a the category that has the largest number\n",
    "# of articles as threshold\n",
    "def get_nb_sentences_by_category():\n",
    "            \n",
    "    # key: category, value: sum of nb sentences over all articles in category\n",
    "    nb_sentences_by_category={}\n",
    "    \n",
    "    for category,articles in category_articles_wcn.items():\n",
    "        if category not in category_articles.keys():\n",
    "            continue\n",
    "        nb_sentences_by_category[category]=0\n",
    "        for article in articles:\n",
    "            if article in article_sections.keys():\n",
    "                for section in article_sections[article]:\n",
    "                    if section in category_top_sections[category]:\n",
    "                        nb_sentences_by_category[category]+=1\n",
    "            \n",
    "    return nb_sentences_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "civil-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sentences_by_category=get_nb_sentences_by_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "verified-environment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American_compositions_and_recordings: 219266 sentences\n",
      "Rock_albums: 143489 sentences\n",
      "Albums_by_American_artists: 137795 sentences\n",
      "Intellectualism: 134236 sentences\n",
      "2nd-millennium_deaths: 127792 sentences\n",
      "Sportsmen: 125770 sentences\n",
      "21st-century_albums: 100620 sentences\n",
      "American_sportsmen: 92968 sentences\n",
      "21st-century_songs: 88096 sentences\n",
      "Populated_places_established_in_the_2nd_millennium: 82493 sentences\n",
      "Works_set_in_outer_space: 81198 sentences\n",
      "Films_set_in_outer_space: 78349 sentences\n",
      "Solar_System_in_film: 77653 sentences\n",
      "19th-century_births: 77158 sentences\n",
      "Earth_in_film: 77154 sentences\n",
      "20th-century_deaths: 75480 sentences\n",
      "Works_about_cities: 74196 sentences\n",
      "Pop_songs: 69435 sentences\n",
      "Rock_albums_by_American_artists: 68780 sentences\n",
      "21st-century_actors: 66235 sentences\n",
      "American_mass_media_people: 64842 sentences\n",
      "American_songs: 64149 sentences\n",
      "Association_football_midfielders: 63057 sentences\n",
      "20th-century_writers: 61032 sentences\n",
      "21st-century_women: 60211 sentences\n",
      "Local_politicians: 57827 sentences\n",
      "British_sportspeople: 57753 sentences\n",
      "American_educators: 56513 sentences\n",
      "People_from_New_Jersey: 53631 sentences\n",
      "Rock_songs: 53087 sentences\n",
      "American_academics: 52849 sentences\n",
      "Association_football_forwards: 52271 sentences\n",
      "Works_about_psychology: 51733 sentences\n",
      "19th-century_European_people: 50778 sentences\n",
      "20th-century_American_people: 48141 sentences\n",
      "Films_set_in_North_America: 47703 sentences\n",
      "Populated_places_established_in_the_19th_century: 47460 sentences\n",
      "Association_football_defenders: 47075 sentences\n",
      "Buildings_and_structures_completed_in_the_20th_century: 46941 sentences\n",
      "Gridiron_football_players: 45968 sentences\n",
      "People_from_the_New_York_metropolitan_area: 45156 sentences\n",
      "Albums_by_British_artists: 44825 sentences\n",
      "Jurists: 44642 sentences\n",
      "20th-century_songs: 44446 sentences\n",
      "Films_set_in_the_United_States: 43944 sentences\n",
      "Works_about_interpersonal_relationships: 43681 sentences\n",
      "Works_about_Europe: 43385 sentences\n",
      "Jazz_albums: 42570 sentences\n",
      "Male_television_actors: 42561 sentences\n",
      "British_footballers: 41182 sentences\n"
     ]
    }
   ],
   "source": [
    "for category, nb_sentences in Counter(nb_sentences_by_category).most_common()[:50]:\n",
    "    print(f\"{category_id_to_title_map[category]}: {nb_sentences} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gross-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "del nb_sentences_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "angry-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_nb_sentences(category_ids):\n",
    "    nb_sentences_in_community=0\n",
    "    # category_articles: articles which contributes to the category section count\n",
    "    articles_in_categories=set().union(*[category_articles_wcn[category_id] for category_id in category_ids])\n",
    "    top_sections_in_categories=set().union(*[category_top_sections[category_id] for category_id in category_ids])\n",
    "    for article in articles_in_categories:\n",
    "        if article in article_sections.keys():\n",
    "            for section in article_sections[article]:\n",
    "                if section in top_sections_in_categories:\n",
    "                    nb_sentences_in_community+=1\n",
    "                \n",
    "    return nb_sentences_in_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "honey-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433150\n"
     ]
    }
   ],
   "source": [
    "categories=[]\n",
    "# those categories seems to be of the same context among categories having the biggest numbers of section contents\n",
    "# therefore we group them together and use the number of unique section contents inside this \"manually grouped\"\n",
    "# community as maximum number of unique section contents as threshold\n",
    "# if at notebook 4 your GPU has not enough memory, rerun notebooks 2 and 3 after decreasing max_nb_sentences\n",
    "for category in ['American_compositions_and_recordings','Albums_by_American_artists','Rock_albums_by_American_artists','Rock_albums','21st-century_albums','21st-century_songs','Pop_songs','American_songs','Rock_songs','20th-century_songs','Jazz_albums']:\n",
    "    categories.append(category_title_to_id_map[category])\n",
    "max_nb_sentences=get_sum_nb_sentences(categories)\n",
    "print(max_nb_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "identical-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(categories,category_articles_dict,article_categories_dict):\n",
    "    \n",
    "    g=nx.Graph()\n",
    "\n",
    "    # get set of all articles which belongs to at least one category in the current connected component/community\n",
    "    articles_belonging_at_least_to_one_category=set().union(*[category_articles_dict[category_id] for category_id in categories])\n",
    "    for article_id in articles_belonging_at_least_to_one_category:\n",
    "        categories_to_connect_in_graph=[category_id for category_id in article_categories_dict[article_id] if category_id in categories]\n",
    "        if len(categories_to_connect_in_graph)==1:\n",
    "            g.add_node(categories_to_connect_in_graph[0])\n",
    "        else:\n",
    "            #   A B C\n",
    "            # A   X X\n",
    "            # B     X\n",
    "            # C \n",
    "            # we iterate in such a way that if we have to connect categories A,B,C we only connect them once\n",
    "            # and do not connect a category with itself\n",
    "            # like shown with the \"X\" on the ascii schema above\n",
    "            for i in range(len(categories_to_connect_in_graph)):\n",
    "                for j in range(i+1,len(categories_to_connect_in_graph)):\n",
    "                    catA=categories_to_connect_in_graph[i]\n",
    "                    catB=categories_to_connect_in_graph[j]\n",
    "                    if not g.get_edge_data(catA,catB):\n",
    "                        g.add_edge(catA,catB,weight=1)\n",
    "                    else:\n",
    "                        old_weight=g.get_edge_data(catA,catB)['weight']\n",
    "                        g.get_edge_data(catA,catB)['weight']=old_weight+1\n",
    "    \n",
    "    # normalize weights\n",
    "    for edge in g.edges:\n",
    "        catA=edge[0]\n",
    "        catB=edge[1]\n",
    "        old_weight=g.get_edge_data(catA,catB)['weight']\n",
    "        n=len(category_articles_dict[catA].union(category_articles_dict[catB]))\n",
    "        # the weight is probability that a randomly picked article in either catA or catB belongs to both categories\n",
    "        # if we use article_categories and category_articles\n",
    "        # or probability that a randomly picked article in either catA or catB contributes to category\n",
    "        # section counts of both categories\n",
    "        # if we use article_categories_wcn and category_articles_wcn\n",
    "        # ie the weight is the Jaccard similarity\n",
    "        g.get_edge_data(catA,catB)['weight']=old_weight/n\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "experimental-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(g,resolution,f_out,first=False):\n",
    "    global community_id\n",
    "    partition=community_louvain.best_partition(g,resolution=resolution)\n",
    "    \n",
    "    com_category_ids={}\n",
    "    for category_id,com in partition.items():\n",
    "        if com not in com_category_ids.keys():\n",
    "            com_category_ids[com]=set()\n",
    "        com_category_ids[com].add(category_id)\n",
    "\n",
    "    for com,category_ids in com_category_ids.items():\n",
    "        sum_nb_sentences_in_commnity=get_sum_nb_sentences(category_ids)\n",
    "        \n",
    "        if sum_nb_sentences_in_commnity>max_nb_sentences and len(category_ids)>1:\n",
    "            if len(category_ids)==2:\n",
    "                for category_id in category_ids:\n",
    "                    f_out.write(json.dumps({'community_id':community_id,'categories':[category_id_to_title_map[category_id]]})+\"\\n\")\n",
    "                    community_id+=1\n",
    "            else:\n",
    "                new_resolution=resolution\n",
    "                if first:\n",
    "                    # after first split, detect communities by using as weight the probability\n",
    "                    # that a randomly picked article in either catA or catB contributes to category\n",
    "                    # section counts of both categories\n",
    "                    g2=build_graph(category_ids,category_articles_wcn,article_categories_wcn)\n",
    "                    for category_id in category_ids:\n",
    "                        del category_articles_wcn[category_id]\n",
    "                else:\n",
    "                \n",
    "                    g2=nx.Graph()\n",
    "                    for comA,comB in g.edges:\n",
    "                        if comA in category_ids and comB in category_ids:\n",
    "                            g2.add_edge(comA,comB,weight=g.get_edge_data(comA,comB)['weight'])\n",
    "\n",
    "                    # if after 2 consecutives splits, the communities remained the same,\n",
    "                    # it means that we have to lower the resolution parameter of the louvain algorithm\n",
    "                    # if we want to split further\n",
    "                    if len(g.nodes)==len(g2.nodes):\n",
    "                        new_resolution=resolution-0.1\n",
    "                split(g2,new_resolution,f_out)\n",
    "        else:\n",
    "            categories_in_community_names=[category_id_to_title_map[category_id] for category_id in category_ids]\n",
    "            f_out.write(json.dumps({'community_id':community_id,'categories':categories_in_community_names})+\"\\n\")\n",
    "            community_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-canal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34eb8a5e4834c0b8d115955f79a9772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "community_id=0\n",
    "with open(\"../data/categories_splitted_into_communities.json\", \"a+\") as f_out:\n",
    "    with open(\"../data/categories_splitted_into_connected_components.json\", \"r\") as f_in:\n",
    "        for line in tqdm(f_in,total = 24061):\n",
    "            json_line=json.loads(line)\n",
    "            categories_in_connected_component=json_line['categories']\n",
    "\n",
    "            if len(categories_in_connected_component)<=2 and get_sum_nb_sentences([category_title_to_id_map[category_name] for category_name in categories_in_connected_component])<=max_nb_sentences:\n",
    "                f_out.write(json.dumps({'community_id':community_id,'categories':categories_in_connected_component})+\"\\n\")\n",
    "                community_id+=1\n",
    "                continue\n",
    "            # convert to ids to use less memory\n",
    "            categories_in_connected_component=set([category_title_to_id_map[category_name] for category_name in categories_in_connected_component])\n",
    "\n",
    "            # first split: detect communities by using as weight probability that a\n",
    "            # randomly picked article in either catA or catB belongs to both categories\n",
    "            g=build_graph(categories_in_connected_component,category_articles,article_categories)\n",
    "            \n",
    "            for category_id in categories_in_connected_component:\n",
    "                del category_articles[category_id]\n",
    "            \n",
    "            split(g,1,f_out,first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-guidance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tm_venv')",
   "language": "python",
   "name": "python39564bittmvenv3226d3cd01364047aed0020f60ff15c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
