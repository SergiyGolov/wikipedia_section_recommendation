{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/dataset_building.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "toxic-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting all article ids...\n"
     ]
    }
   ],
   "source": [
    "nb_articles=len(get_all_articles(\"../data/article_categories_no_unknown_types.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "preceding-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "# some characters were still in the escaped html form, we build a mapping table to be applied with str.replace\n",
    "def get_escaped_html_mapping_table():\n",
    "    escaped_html=re.compile(r'&\\w+;')\n",
    "    escaped_html_chars=set()\n",
    "    with open(\"../data/article_section_sentences.json\", \"r\") as f_in:\n",
    "        for line in tqdm(f_in,total=nb_articles):\n",
    "            json_line=json.loads(line)\n",
    "            article_id=json_line['article_id']\n",
    "            section_sentences=json_line['section_sentences']\n",
    "            section_sentences_ascii=[]\n",
    "\n",
    "            for section_sentence in section_sentences:\n",
    "                section=section_sentence['section']\n",
    "                escaped=set(re.findall(escaped_html,section_sentence['sentence']))\n",
    "                escaped_html_chars|=escaped\n",
    "                \n",
    "    escaped_html_mapping_table={}\n",
    "    for char in escaped_html_chars:\n",
    "        unescaped_char=html.unescape(char)\n",
    "        if unescaped_char!=char:\n",
    "            escaped_html_mapping_table[char]=unescaped_char\n",
    "    \n",
    "    return escaped_html_mapping_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "computational-scheduling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193af9895a8f4b59b98535d585515358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "escaped_html_mapping_table=get_escaped_html_mapping_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "grateful-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "# https://stackoverflow.com/a/41516221\n",
    "# translate \"fancy\" quotation marks and dashes to ascii quotation marks and dashes, \n",
    "# in order to avoid that e.g. \"1823–1967\" becomes \"1823 1967\"\n",
    "transl_table = dict( [ (ord(x), ord(y)) for x,y in zip( u\"‘’´“”«»–—−–-\",  u\"'''\\\"\\\"\\\"\\\"-----\") ] )\n",
    "\n",
    "regex_multiple_spaces=re.compile(r\"\\s{2,}\")\n",
    "# eg ( , )\n",
    "regex_comma_between_parentheses=re.compile(r\"\\(\\s*,\\s*\\)\")\n",
    "# eg \"( , Cha ngwu We iyua nhui )\" => \"( Cha ngwu We iyua nhui )\"\n",
    "# because non-ascii characters before the comma were removed\n",
    "regex_text_after_comma_between_parentheses=re.compile(r\"\\(\\s*,(.+)\\)\")\n",
    "# some sections had only one \"=\" around them, but sections should have at least 2 \"=\",\n",
    "# therefore those are mistakes because all correct sections were transformed into <hX> html tags by wikiextractor\n",
    "regex_wrong_sections=re.compile(r\"\\=[\\w\\s]+\\=\")\n",
    "\n",
    "printable = set(string.printable)\n",
    "\n",
    "# https://stackoverflow.com/a/517974\n",
    "# the idea was to replace diacritics from european languages with its ascii form (e.g. \"à\" => \"a\"),\n",
    "# without using a module like unidecode which would translate e.g. arabic or japanese kanji to\n",
    "# non-existant words in english which are not even phonetically the same as in the original language\n",
    "# therefore all letters which cannot be easily converted into ascii are removed\n",
    "def remove_accents(input_str):\n",
    "    output_str=str(input_str)\n",
    "    for escaped_char,unescaped_char in escaped_html_mapping_table.items():\n",
    "        output_str=output_str.replace(escaped_char,unescaped_char)\n",
    "    output_str=input_str.translate( transl_table )\n",
    "    nfkd_form = unicodedata.normalize('NFKD', output_str)\n",
    "    output_str=\"\".join([c if not unicodedata.combining(c) else \" \" for c in nfkd_form])\n",
    "    output_str=\"\".join([c if c in printable else \" \" for c in output_str])\n",
    "    # some dashes were not correctly unescaped, therefore we need to replace the escaped version with a normal dash\n",
    "    output_str=output_str.replace(\"&mdash;\",\"-\")\n",
    "    output_str=re.sub(regex_wrong_sections,r\" \",output_str)\n",
    "    output_str=re.sub(regex_comma_between_parentheses,r\" \",output_str)\n",
    "    output_str=re.sub(regex_text_after_comma_between_parentheses,r\"(\\1)\",output_str)\n",
    "    output_str=re.sub(regex_multiple_spaces,r\" \",output_str)\n",
    "    output_str=output_str.replace(\"( )\",\"\").replace(\"()\",\"\").replace(\"( \",\"(\").replace(\" )\",\")\")\n",
    "    output_str=output_str.replace(\" , \",\", \").replace('\" \"','').replace(\" .\",\".\")\n",
    "    return output_str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "lesbian-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikiextractor didn't managed to remove all tables from articles,\n",
    "# therefore some sentence contain noise left by badly extracted tables\n",
    "# we detect and remove those sentences\n",
    "# e.g. style=\\\"text-align:center;\\\" colspan=2| Career !\n",
    "# e.g. 9 || || 14 ||.377 ||.250 ||.677 || 2.9 || 0.6|| 0.2 ||0.1 || 4.0\n",
    "def check_if_sentence_contain_table(sentence):\n",
    "    return \"colspan\" in sentence or \"style=\" in sentence or \"rowspan\" in sentence or \"style =\" in sentence or \"||\" in sentence or \"<!-\" in sentence or 'scope=\"' in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aggressive-ballet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d104dec3b0c047ee9e0bef0dfaa71d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with open(\"../data/article_section_sentences_ascii.json\", \"a+\") as f_out:\n",
    "    with open(\"../data/article_section_sentences.json\", \"r\") as f_in:\n",
    "        for line in tqdm(f_in,total=nb_articles):\n",
    "            json_line=json.loads(line)\n",
    "            article_id=json_line['article_id']\n",
    "            section_sentences=json_line['section_sentences']\n",
    "            section_sentences_ascii=[]\n",
    "\n",
    "            for section_sentence in section_sentences:\n",
    "                section=section_sentence['section']\n",
    "                \n",
    "                sentence_ascii=remove_accents(section_sentence['sentence'])\n",
    "                if check_if_sentence_contain_table(sentence_ascii) or sum([c.isalpha() for c in sentence_ascii]) == 0:\n",
    "                    continue\n",
    "                section_sentences_ascii.append({'section':section,'sentence':sentence_ascii})\n",
    "\n",
    "            if len(section_sentences_ascii)>0:\n",
    "                f_out.write(json.dumps({'article_id':article_id,'section_sentences':section_sentences_ascii})+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-tamil",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tm_venv')",
   "language": "python",
   "name": "python39564bittmvenv3226d3cd01364047aed0020f60ff15c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
