{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uniform-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/dataset_building.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vital-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f2d59136214acfa0d8dc62ed48cbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sparql\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "# key: type subclass name, value: type superclass name\n",
    "# the dict will be used to map subclasses to superclasses by going up in the hierarchy\n",
    "# until each subclass is translated to a top-level superclass\n",
    "class_hierarchy_dict={}\n",
    "\n",
    "# 200 requests are more than enough, the last ones (after ~150) returned empty responses\n",
    "for offset in trange(200):\n",
    "    # select all subclass-superclass relations in DBPedia\n",
    "    # 10000 is the maximum allowed amount of results by query, therefore to get all the relations,\n",
    "    # we apply offsets in the result indexes\n",
    "    q = (f\"\"\"select ?subclass ?superclass {{\n",
    "        ?subclass rdfs:subClassOf ?superclass\n",
    "        }}\n",
    "        limit 10000\n",
    "        offset {offset*10000}\"\"\")\n",
    "    result = sparql.query('http://dbpedia.org/sparql', q).fetchall()\n",
    "    for row in result:\n",
    "        subclass = row[0].value\n",
    "        superclass = row[1].value\n",
    "        if subclass.startswith(\"http://dbpedia.org/ontology/\") and (superclass.startswith(\"http://dbpedia.org/ontology/\") or superclass.endswith(\"Thing\")):\n",
    "            subclass=subclass.split(\"/\")[-1]\n",
    "            superclass=superclass.split(\"/\")[-1]\n",
    "            \n",
    "            # the initial idea was that a subclass could have multiple superclasses therefore\n",
    "            # the superclasses were stored in a set for each subclass\n",
    "            if subclass not in class_hierarchy_dict.keys():\n",
    "                class_hierarchy_dict[subclass]=set()\n",
    "            class_hierarchy_dict[subclass].add(superclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "superb-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the maximum superclass set length is 1 it means that each subclass has only one superclass\n",
    "max([len(superclasses) for superclasses in class_hierarchy_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "antique-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subclass,superclasses in class_hierarchy_dict.items():\n",
    "    # actually each sublass had only one single superclass, therefore we transform the superclass sets to strings\n",
    "    class_hierarchy_dict[subclass] = \"\".join(superclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "modular-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_json(class_hierarchy_dict,\"../data/type_hierarchy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "religious-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-level DBPedia types have \"owl#Thing\" as superclass\n",
    "toplevel_types=set([subclass for subclass,superclass in class_hierarchy_dict.items() if superclass == 'owl#Thing'])\n",
    "# \"Agent\" is too general to be used as type (as described in the original paper), \n",
    "# therefore we include Agent's subclasses in top-level types\n",
    "toplevel_types|=set([subclass for subclass,superclass in class_hierarchy_dict.items() if superclass == 'Agent'])\n",
    "toplevel_types.remove('Agent')\n",
    "\n",
    "# there were some articles that had \"TimeInterval\" as type, and this type has no superclass\n",
    "toplevel_types.add(\"TimeInterval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "palestinian-ordinance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(toplevel_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "enclosed-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all top-level types that were used in the original paper\n",
    "epfl_types=set()\n",
    "nb_articles_with_type_2017=0\n",
    "with open(\"../data/epfl_paper/article_types_dbpedia.tsv\") as file:\n",
    "    for line in file:\n",
    "        article_type=line.split()[0]\n",
    "        epfl_types.add(article_type)\n",
    "        nb_articles_with_type_2017+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "binary-domain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NaturalEvent'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if our top-level types match those used in the original paper\n",
    "epfl_types-toplevel_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conventional-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Algorithm',\n",
       " 'Altitude',\n",
       " 'Area',\n",
       " 'Award',\n",
       " 'Blazon',\n",
       " 'Browser',\n",
       " 'ChartsPlacements',\n",
       " 'Cipher',\n",
       " 'Colour',\n",
       " 'Currency',\n",
       " 'Deity',\n",
       " 'Demographics',\n",
       " 'Depth',\n",
       " 'Diploma',\n",
       " 'Disease',\n",
       " 'ElectionDiagram',\n",
       " 'Employer',\n",
       " 'EthnicGroup',\n",
       " 'Family',\n",
       " 'FictionalCharacter',\n",
       " 'FileSystem',\n",
       " 'Flag',\n",
       " 'GeneLocation',\n",
       " 'GrossDomesticProduct',\n",
       " 'GrossDomesticProductPerCapita',\n",
       " 'Identifier',\n",
       " 'List',\n",
       " 'Media',\n",
       " 'MedicalSpecialty',\n",
       " 'Medicine',\n",
       " 'PersonFunction',\n",
       " 'Population',\n",
       " 'Protocol',\n",
       " 'PublicService',\n",
       " 'Relationship',\n",
       " 'Spreadsheet',\n",
       " 'StarCluster',\n",
       " 'Statistic',\n",
       " 'Tank',\n",
       " 'TimeInterval',\n",
       " 'Unknown'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any new top-level types since 2017\n",
    "toplevel_types-epfl_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "trying-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_to_get=set()\n",
    "\n",
    "# key: article id, value: article title\n",
    "article_id_title_dict={}\n",
    "# key: article title, value: article id\n",
    "article_title_id_dict={}\n",
    "\n",
    "article_ids_titles_tuple_list=read_tuple_list_from_file((int,str),\"../data/article_ids_titles.tsv\")\n",
    "\n",
    "for article_id,article_title in article_ids_titles_tuple_list:\n",
    "    article_titles_to_get.add(article_title)\n",
    "    article_title_id_dict[article_title]=article_id\n",
    "    article_id_title_dict[article_id]=article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "developing-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "article_title_type_dict={}\n",
    "with open(\"../data/instance-types_lang=en_specific.ttl\") as file:  \n",
    "    # line example: <http://dbpedia.org/resource/Étude_Op._25,_No._2_(Chopin)> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/ClassicalMusicComposition> .\n",
    "    for line in file:\n",
    "        splited_line=line.split()\n",
    "        # resource name example in file: <http://dbpedia.org/resource/Étude_Op._25,_No._2_(Chopin)>\n",
    "        # we need to extract Étude_Op._25,_No._2_(Chopin):\n",
    "        resource_name=urllib.parse.unquote(splited_line[0].split(\"/\")[-1][:-1])\n",
    "        # dbpedia type example in file: <http://www.w3.org/2002/07/ClassicalMusicComposition>\n",
    "        # we need to extract ClassicalMusicComposition:\n",
    "        dbpedia_type=splited_line[2].split(\"/\")[-1][:-1]\n",
    "        if resource_name in article_titles_to_get and dbpedia_type!=\"owl#Thing\" and dbpedia_type!=\"Agent\":\n",
    "            # we translate subclass types to superclass types until we reach the top of the class hierarchy\n",
    "            while dbpedia_type not in toplevel_types:\n",
    "                dbpedia_type=class_hierarchy_dict[dbpedia_type]\n",
    "            article_title_type_dict[resource_name]=dbpedia_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "roman-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_types_set=set(article_title_type_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "facial-jerusalem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NaturalEvent'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all top-level types used in the original paper were retrieved\n",
    "epfl_types-retrieved_types_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "differential-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Award',\n",
       " 'Colour',\n",
       " 'Currency',\n",
       " 'Disease',\n",
       " 'EthnicGroup',\n",
       " 'FictionalCharacter',\n",
       " 'Identifier',\n",
       " 'MedicalSpecialty',\n",
       " 'TimeInterval'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which top-level types were added since 2017\n",
    "retrieved_types_set-epfl_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "proper-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple list needed as input for the WCNPruning tool in this form: (article id, article type)\n",
    "article_ids_types=[]\n",
    "for article_title,article_type in article_title_type_dict.items():\n",
    "    article_id=article_title_id_dict[article_title]\n",
    "    article_ids_types.append((article_id,article_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "chief-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tuple_list_to_file(article_ids_types,\"../data/article_types.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "computational-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5774875100007044"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which proportion of articles have a defined type\n",
    "len(article_ids_types)/len(article_titles_to_get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids_2017=set()\n",
    "with open(\"../data/epfl_paper/article_categories_sept17.tsv\") as file:\n",
    "    for line in file:\n",
    "        article_ids_2017.add(int(line.split()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "unable-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5259709994922241"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which proportion of articles had a defined type in 2017\n",
    "nb_articles_with_type_2017/len(article_ids_2017)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
